#!/usr/bin/env python3
# vim: set ts=8 sts=4 et sw=4 tw=99:
#
# Probes for new meets from the FPR
#

from bs4 import BeautifulSoup
import os
import sys

try:
    import oplprobe
except ImportError:
    sys.path.append(os.path.join(os.path.dirname(os.path.dirname(
        os.path.dirname(os.path.realpath(__file__)))), "scripts"))
    import oplprobe


MAIN_URLS = [
    'http://fpr-info.ru/___protokoly/prot_2020/prot_2020.htm',
    'http://fpr-info.ru/___protokoly/prot_2019/prot_2019.htm',
    'http://fpr-info.ru/___protokoly/prot_2018/prot_2018.htm',
    'http://fpr-info.ru/___protokoly/prot_2017/prot_2017.htm',
    'http://fpr-info.ru/___protokoly/prot_2016/prot_2016.htm',
    'http://fpr-info.ru/___protokoly/prot_2015/prot_2015.htm',
    'http://fpr-info.ru/___protokoly/prot_2014/prot_14.htm',
    'http://fpr-info.ru/___protokoly/prot_2013/prot_13.htm',
    'http://fpr-info.ru/___protokoly/prot_2012/prot_12.htm',
    'http://fpr-info.ru/___protokoly/prot_2011/prot_11.htm',
    'http://fpr-info.ru/___protokoly/prot_2010/prot_10.htm',
    'http://fpr-info.ru/___protokoly/prot_2009/prot_09.htm',
    'http://fpr-info.ru/___protokoly/prot_2008/prot_08.htm',
    'http://fpr-info.ru/___protokoly/prot_2007/prot_07.htm'
]

SPB_URL = 'http://www.powerliftingfed.spb.ru/protocols'

FPIO_URL = 'http://fpio.org.ru/index.php?menu=7'

NSO_URL = 'http://fp-nso.ru/%d0%b4%d0%be%d0%ba%d1%83%d0%bc%d0%b5%d0%bd%d1%82%d1%8b/'\
          '%d0%bf%d1%80%d0%be%d1%82%d0%be%d0%ba%d0%be%d0%bb%d1%8b/'


FEDDIR = os.path.dirname(os.path.realpath(__file__))


def colour(s):
    return "\033[1;33m" + s + "\033[0;m"


# FPR has malformed html on their results page, remove the extra tags
def fix_html(html):
    tag_dict = {}
    remove_tags = []

    ii = 0
    split_html = html.split('<')

    # Find unopened tags
    for tag_start in split_html:
        if tag_start != '':
            if tag_start[0] == '/':  # Close tag
                close_idx = tag_start.find(">")
                tag_type = tag_start[1:tag_start.find(">")]
                if tag_type not in tag_dict:
                    remove_tags.append(ii)
                elif tag_dict[tag_type] == 0:
                    remove_tags.append(ii)
                else:
                    tag_dict[tag_type] -= 1

            elif '/>' not in tag_start and tag_start[0] != 'p':  # Open tag
                close_idx = tag_start.find(">")
                tag_type = tag_start[0:tag_start.find(">")].split(" ")[0]
                if tag_type not in tag_dict:
                    tag_dict[tag_type] = 1
                else:
                    tag_dict[tag_type] += 1
        ii = ii + 1

    # Remove the unopened tags
    for idx in remove_tags:
        close_idx = split_html[idx].find(">")
        if len(split_html[idx]) > close_idx + 1:
            split_html[idx] = split_html[idx][close_idx + 1:]
        else:
            split_html[idx] = ''

    split_html = ["<" + line for line in split_html if line != '']
    return ''.join(split_html)


def getmeetlist(html, main_url):
    base_url = main_url.rsplit('/', 1)[0]

    html = fix_html(str(html, 'windows-1251'))

    soup = BeautifulSoup(html, 'html.parser')
    divs = soup.find_all("table", {"width": "101%"})

    # Pre 2010 the tables are slightly different
    if divs == []:
        divs = soup.find_all("table", {"id": "table2"})  # 07
    if divs == []:
        divs = soup.find_all("table", {"id": ["table7", "table4"]})  # 08
    if divs == []:
        divs = soup.find_all("table", {"id": ["table11", "table12"]})  # 09
    if divs == []:
        divs = soup.find_all("table", {"width": "102%"})

    urls = []
    for div in divs:
        for a in div.find_all('a'):
            url = a['href']

        # Non relative links are meet photos and international meets, mir
        # =Worlds,evr =Euros
            if not any(test_str in url for test_str in ['http', 'mir', 'arnold', 'evr']):
                url = base_url + "/" + url
                url = url.replace('.com//', '/')
                if url not in urls:
                    urls.append(url)
    return urls


def getmeetlist_SPB(html, main_url):
    base_url = main_url.rsplit('/', 1)[0]
    soup = BeautifulSoup(html, 'html.parser')
    divs = soup.find_all('div', {'class', 'list-group'})
    urls = []
    for div in divs:
        for a in div.find_all('a'):
            url = a['href']
            url = base_url + "/" + url
            url = url.replace('.ru//', '.ru/')
            if url not in urls:
                urls.append(url)
    return urls


def getmeetlist_FPIO(html, main_url):
    base_url = main_url.rsplit('/', 1)[0]
    soup = BeautifulSoup(html, 'html.parser')
    divs = soup.find_all('div', {'class', 'doc_block_max'})
    urls = []
    for div in divs:
        for a in div.find_all('a'):
            url = a['href']
            url = base_url + "/" + url
            url = url.replace('.ru//', '.ru/')
            if 'allpowerlifting' in url:
                continue
            elif '.rus.' in url or '-rus-' in url:
                continue
            if url not in urls:
                urls.append(url)
    return urls


def getmeetlist_NSO(html, main_url):
    soup = BeautifulSoup(html, 'html.parser')
    divs = soup.find_all('div', {'class', 'entry-content'})
    urls = []
    for div in divs:
        for a in div.find_all('a'):
            url = a['href']
            if 'addtoany' in url:
                continue
            if url not in urls:
                urls.append(url)
    return urls


def main():

    meetlist = []
    for url in MAIN_URLS:
        html = oplprobe.gethtml(url)
        meetlist = meetlist + getmeetlist(html, url)

    html_SPB = oplprobe.gethtml(SPB_URL)
    meetlist = meetlist + getmeetlist_SPB(html_SPB, SPB_URL)

    html_FPIO = oplprobe.gethtml(FPIO_URL)
    meetlist = meetlist + getmeetlist_FPIO(html_FPIO, FPIO_URL)

    html_NSO = oplprobe.gethtml(NSO_URL)
    meetlist = meetlist + getmeetlist_NSO(html_NSO, NSO_URL)

    entered = oplprobe.getenteredurls(FEDDIR)
    unentered = oplprobe.getunenteredurls(meetlist, entered)

    oplprobe.print_meets(colour('[FPR]'), unentered)


if __name__ == '__main__':
    main()
