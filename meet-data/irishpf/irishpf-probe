#!/usr/bin/env python3
# vim: set ts=8 sts=4 et sw=4 tw=99:
#
# Probes the IrishPF website for any new meets.


from bs4 import BeautifulSoup
import datetime
import os
import shutil
import sys
import urllib.request


NUMPAGES = 1  # Number of pages to go back in results, 10 results per page.
FEDDIR = os.path.dirname(os.path.realpath(__file__))
FEDURL = "http://www.irishpowerliftingfederation.com/competitions/results/"


def getpageurl(n):
    return FEDURL + "&tribe_paged=" + str(n)


def error(msg):
    print(msg, file=sys.stderr)
    sys.exit(1)


def color(s):
    return "\033[1;32m" + s + "\033[0;m"


def gethtml(url):
    with urllib.request.urlopen(url) as r:
        return r.read()


def getmeetlist(html):
    # The HTML is malformed, for example as follows:
    #   <p><a href="foo"></p><p></a></p>
    # Work around this by deleting all the <p> tags.
    html = str(html, 'utf-8')
    html = html.replace('<p>', '')
    html = html.replace('</p>', '')

    soup = BeautifulSoup(html, 'html.parser')
    content = soup.find("div", {"class": "entry-content"})

    urls = []
    for a in content.find_all('a'):
        url = a['href']
        if not url in urls:
            urls.append(url)

    return urls


def getenteredurls():
    urls = []
    for dirname, subdirs, files in os.walk(FEDDIR):
        if 'URL' in files:
            with open(dirname + os.sep + 'URL', 'r') as fd:
                for k in fd.readlines():
                    urls.append(k.strip())
    return urls


def main():
    # The main page contains a list of URLs to per-year results pages.
    yearpages = getmeetlist(gethtml(FEDURL))

    meetlist = []
    for url in yearpages:
        meets = getmeetlist(gethtml(url))
        meetlist = meetlist + meets

    known = getenteredurls()

    for m in meetlist:
        if not m in known:
            print(color('[IrishPF] ') + m)

if __name__ == '__main__':
    main()
