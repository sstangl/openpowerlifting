#!/bin/bash

set -e

if [ $# -ne 1 ]; then
	echo " Usage: $0 http://url/to/results/page"
	exit 1
fi

SCRIPTDIR="$( cd "$( dirname "${BASH_SOURCE[0]}" )" && pwd )"
REPOSCRIPTDIR="${SCRIPTDIR}/../../scripts"

# Download the website, keep the original name so sheet references work
wget --output-document=main.html "$1"

# Save the website URL for future use, since it's pretty hard to tell
# what meets on the site are tracked and which aren't.
echo "$1" > URL


# Sometimes the documents are encoded in WINDOWS-1251.
file main.html | grep ISO-8859 && iconv -f WINDOWS-1251 -t UTF-8 main.html > main2.html
if [ -f main2.html ]; then
	mv main2.html main.html
fi


# Get the links to the individual sheets from the results file
mapfile -t sheet_links < <( ${SCRIPTDIR}/wpa-ukr-get-sheet-links main.html )

#Now that we have the sheet links we no longer need the containing page
rm main.html

r_nums=($(seq 1 1 $((${#sheet_links[@]}/2)))) 
if [ ${#sheet_links[*]}/2 == 1 ];then #Only number the result files if there is more than one
	r_nums[0]=''
fi

if [ -f results.csv ]; then
	rm results.csv
fi




#Expand the sheet links into full paths
for (( ii=0; ii!= $((${#sheet_links[@]}/2)) ;++ii))
do
  wget --output-document="results"${r_nums[$ii]}".html" ${1%/*}"/"${sheet_links[$((2*ii+1))]} #Link is every second line

    #file is returning 8859 when it's formatted in 1251 for some reason
    file "results"${r_nums[$ii]}".html" | grep ISO-8859 && iconv -f WINDOWS-1251 -t UTF8 "results"${r_nums[$ii]}".html" > temp.html
    if [ -f temp.html ]; then
	    mv temp.html "results"${r_nums[$ii]}".html"
	    sed -i -e 's/charset=windows-1251/charset=UTF-8/g' "results"${r_nums[$ii]}".html"
    fi


     cp "results"${r_nums[$ii]}".html" "results"${r_nums[$ii]}".xls"

	# Replace any commas in the xls file with periods.
	# Commas are used as decimal points in the European style.
	sed -i -e 's/,/\./g' "results"${r_nums[$ii]}".xls"

	# Strikethrough HTML is used to denote failures.
	# Replace <s> with '-' and remove </s>.
	sed -i -e 's/<s>/-/g' "results"${r_nums[$ii]}".xls" 
	sed -i -e 's/<\/s>//g' "results"${r_nums[$ii]}".xls"

	# ASCII 0xa0 (a space) creeps in everywhere for no good reason.
	#Replacing this is creating corrupted characters for some reason
	#sed -i -e 's/\xa0//g' "results"${r_nums[$ii]}".xls"


	# Disqualifications use ascii 0x97, a long dash.
	sed -i -e 's/\x97/DQ/g' "results"${r_nums[$ii]}".xls"

	# Use LibreOffice to automatically convert the <table> to a csv file.
	# This creates results.csv.
	libreoffice --headless --convert-to csv --infilter=CSV:44,34,UTF8 "results"${r_nums[$ii]}".xls"

	rm "results"${r_nums[$ii]}".html" "results"${r_nums[$ii]}".xls"



	# Remove redundant spacing.
	sed -i -e 's/  / /g' "results"${r_nums[$ii]}".csv"
	sed -i -e 's/, /,/g' "results"${r_nums[$ii]}".csv"
	sed -i -e 's/ ,/,/g' "results"${r_nums[$ii]}".csv"

	# Failures are denoted as "X", when we just want a blank space.
	sed -i -e 's/,X,/,,/g' "results"${r_nums[$ii]}".csv"

	# Skips are sometimes denotes as "#"
	sed -i -e 's/#//g' "results"${r_nums[$ii]}".csv"

	# Birth year sometimes has a question mark
	sed -i -e 's/,?,/,,/g' "results"${r_nums[$ii]}".csv"




	#Now write the sheet name to the first line
	echo -e 'Sheet '$ii': '${sheet_links[$((2*ii))]}'\n' | cat - 'results'${r_nums[$ii]}'.csv' > temp && mv temp 'results'${r_nums[$ii]}'.csv'

    #Now combine all the sheets into one big csv
	cat 'results'${r_nums[$ii]}'.csv' >> results.csv
	echo >> results.csv

	rm 'results'${r_nums[$ii]}'.csv'
done


# Commands after this point were extracted into a separate file
# since they had to be re-run by hand in case of error.
${SCRIPTDIR}/wpa-ukr-parse-post
