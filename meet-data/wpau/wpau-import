#!/bin/bash

set -e

if [ $# -ne 2 ]; then
	echo " Usage: $0 dirname url"
	exit 1
fi

SCRIPTDIR="$( cd "$( dirname "${BASH_SOURCE[0]}" )" && pwd )"
REPOSCRIPTDIR="${SCRIPTDIR}/../../scripts"


mkdir "$1"
cd "$1"

# Download the website, keep the original name so sheet references work
wget --output-document=main.html "$2"

# Save the website URL for future use, since it's pretty hard to tell
# what meets on the site are tracked and which aren't.
echo "$2" > URL


# Sometimes the documents are encoded in WINDOWS-1251.
file main.html | grep ISO-8859 && iconv -f WINDOWS-1251 -t UTF-8 main.html > main2.html
if [ -f main2.html ]; then
	mv main2.html main.html
fi


# Get the links to the individual sheets from the results file
mapfile -t sheet_links < <( ${SCRIPTDIR}/wpau-get-sheet-links main.html )

#Now that we have the sheet links we no longer need the containing page
rm main.html

r_nums=($(seq 1 1 $((${#sheet_links[@]}/2)))) 
if [ ${#sheet_links[*]}/2 == 1 ];then #Only number the result files if there is more than one
	r_nums[0]=''
fi

if [ -f results.csv ]; then
	rm results.csv
fi




#Expand the sheet links into full paths
for (( ii=0; ii!= $((${#sheet_links[@]}/2)) ;++ii))
do
  wget --output-document="results"${r_nums[$ii]}".html" ${2%/*}"/"${sheet_links[$((2*ii+1))]} #Link is every second line

    #file is returning 8859 when it's formatted in 1251 for some reason
    file "results"${r_nums[$ii]}".html" | grep ISO-8859 && iconv -f WINDOWS-1251 -t UTF8 "results"${r_nums[$ii]}".html" > temp.html
    if [ -f temp.html ]; then
	    mv temp.html "results"${r_nums[$ii]}".html"
	    sed -i -e 's/charset=windows-1251/charset=UTF-8/g' "results"${r_nums[$ii]}".html"
    fi


     cp "results"${r_nums[$ii]}".html" "results"${r_nums[$ii]}".xls"

	# Replace any commas in the xls file with periods.
	# Commas are used as decimal points in the European style.
	sed -i -e 's/,/\./g' "results"${r_nums[$ii]}".xls"

	# Strikethrough HTML is used to denote failures.
	# Replace <s> with '-' and remove </s>.
	sed -i -e 's/<s>/-/g' "results"${r_nums[$ii]}".xls" 
	sed -i -e 's/<\/s>//g' "results"${r_nums[$ii]}".xls"

    #Convert red background to fails
    sed -i -e 's/<font color="#000000">//g' "results"${r_nums[$ii]}".xls"
    sed -i -e 's/bgcolor="#FF0000".*sdnum="3081;">/sdnum="3081;">-/g' "results"${r_nums[$ii]}".xls"


	# Use LibreOffice to automatically convert the <table> to a csv file.
	# This creates results.csv.
	libreoffice --headless --convert-to csv --infilter=CSV:44,34,UTF8 "results"${r_nums[$ii]}".xls"

	rm "results"${r_nums[$ii]}".html" "results"${r_nums[$ii]}".xls"

	# ASCII 0xa0 (a space) creeps in everywhere for no good reason.
	#Using \xa0 was corrupting characters for some reason
	sed -i -e 's/Â //g' "results"${r_nums[$ii]}".csv"

	# Remove redundant spacing.
	sed -i -e 's/  / /g' "results"${r_nums[$ii]}".csv"
	sed -i -e 's/, /,/g' "results"${r_nums[$ii]}".csv"
	sed -i -e 's/ ,/,/g' "results"${r_nums[$ii]}".csv"

	# Failures are denoted as "X", when we just want a blank space.
	sed -i -e 's/,X,/,,/g' "results"${r_nums[$ii]}".csv"

	# Skips are sometimes denotes as "#"
	sed -i -e 's/#//g' "results"${r_nums[$ii]}".csv"

	# Birth year sometimes has a question mark
	sed -i -e 's/,?,/,,/g' "results"${r_nums[$ii]}".csv"

    actualsize=$(wc -c <'results'${r_nums[$ii]}'.csv')
    
    #Check that the sheet isn't empty
    if [ $actualsize -ge 2 ]; then
		# #Now write the sheet name to the first line
		echo -e 'Sheet '$ii': '${sheet_links[$((2*ii))]}'\n' | cat - 'results'${r_nums[$ii]}'.csv' > temp && mv temp 'results'${r_nums[$ii]}'.csv'

	    #Now combine all the sheets into one big csv
		cat 'results'${r_nums[$ii]}'.csv' >> results.csv
		echo >> results.csv
	fi
	rm 'results'${r_nums[$ii]}'.csv'
done


if [ ${#sheet_names[*]} == 1 ]; then
	echo -e 'Sheet 1: '$sheet_names'\n' | cat - results.csv > temp && mv temp results.csv
fi


# Commands after this point were extracted into a separate file
# since they had to be re-run by hand in case of error.
${SCRIPTDIR}/wpau-parse-post
