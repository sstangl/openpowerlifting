#!/usr/bin/env python3
# vim: set ts=8 sts=4 et sw=4 tw=99:
#
# Compiles all entries.csv and meet.csv files into the final files.
#

from oplcsv import Csv
from usernames import get_username
import os
import sys


MEETID = 0


def nextmeetid():
    global MEETID
    x = MEETID
    MEETID = MEETID + 1
    return x


LIFTERID = 1  # Due to default seed of LIFTERIDMAP below.


def nextlifterid():
    global LIFTERID
    x = LIFTERID
    LIFTERID = LIFTERID + 1
    return x


# Global map of (Name => LifterID) mappings.
LIFTERIDMAP = {
    'Sean Stangl': 0
}


def get_lifterid(name):
    global LIFTERIDMAP
    try:
        return LIFTERIDMAP[name]
    except KeyError:
        lifterid = nextlifterid()
        LIFTERIDMAP[name] = lifterid
        return lifterid


# Reads in the map Name => Birthday (as date string).
def make_birthdays_map(lifterdir):
    csv = Csv(lifterdir + os.sep + 'birthdays.csv')

    nameidx = csv.index('Name')
    birthdayidx = csv.index('Birthday')

    birthdays = dict()
    for row in csv.rows:
        birthdays[row[nameidx]] = row[birthdayidx]

    return birthdays


# Fills in the Age column from the BirthYear column if possible.
# Inexact ages derived in this way are noted as '.5', for example '23.5',
# designating "either 23 or 24".
def age_from_birthyear(csv, date):
    if 'BirthYear' not in csv.fieldnames:
        return

    if 'Age' not in csv.fieldnames:
        csv.append_column('Age')

    birthyearidx = csv.index('BirthYear')
    ageidx = csv.index('Age')
    [year, month, day] = date.split('-')

    for row in csv.rows:
        if row[birthyearidx] and not row[ageidx]:
            lower_age = int(year) - int(row[birthyearidx]) - 1
            assert lower_age < 120
            assert lower_age > 3
            row[ageidx] = str(lower_age) + '.5'


# Fills in the Age column from the Birthday.
def age_from_birthday(csv, date, birthdays):
    if 'Age' not in csv.fieldnames:
        csv.append_column('Age')

    nameidx = csv.index('Name')
    ageidx = csv.index('Age')
    [year, month, day] = date.split('-')

    for row in csv.rows:
        name = row[nameidx]

        # Hardcoded ages take precedence.
        if row[ageidx] or name not in birthdays:
            continue

        [birthyear, birthmonth, birthday] = birthdays[name].split('-')
        assert birthyear < year

        years = int(year) - int(birthyear)
        if (int(month) < int(birthmonth) or
                (int(month) == int(birthmonth) and
                    int(day) <= int(birthday))):
            years -= 1

        row[ageidx] = str(years)


# Appends to entriescsv and meetscsv, while assigning a MeetID mapping.
def addmeet(entriescsv, meetscsv, entriespath, meetpath, birthdays):
    newentries = Csv(entriespath)
    newmeet = Csv(meetpath)

    # Remove some columns that are allowed as data but are ignored.
    newentries.remove_column_by_name("Country")
    newentries.remove_column_by_name("School")
    newentries.remove_column_by_name("Team")
    newentries.remove_column_by_name("State")
    newentries.remove_column_by_name("InternationalName")
    newentries.remove_column_by_name("Country-State")
    newentries.remove_column_by_name("College/University")
    newentries.remove_column_by_name("Tested")
    newentries.remove_column_by_name("AgeClass")

    # Add the MeetID.
    assert "MeetID" in entriescsv.fieldnames
    assert "MeetID" in meetscsv.fieldnames
    assert "MeetID" not in newentries.fieldnames
    assert "MeetID" not in newmeet.fieldnames

    meetid = str(nextmeetid())

    newentries.append_column('MeetID')
    idx = newentries.index('MeetID')
    for row in newentries.rows:
        row[idx] = meetid

    newmeet.append_column('MeetID')
    idx = newmeet.index('MeetID')
    for row in newmeet.rows:
        row[idx] = meetid

    # Derive the path (e.g., "uspa/0039").
    # Input looks like "meet-path/uspa/0039/meet.csv".
    assert "MeetPath" not in newmeet.fieldnames
    path = meetpath[meetpath.index(
        os.sep) + 1: meetpath.rindex(os.sep)].replace(os.sep, '/')
    assert ',' not in path

    newmeet.append_column("MeetPath")
    idx = newmeet.index("MeetPath")
    for row in newmeet.rows:
        row[idx] = path

    # Add the LifterIDs.
    newentries.append_column('LifterID')
    idx = newentries.index('LifterID')
    nameidx = newentries.index('Name')
    for row in newentries.rows:
        row[idx] = str(get_lifterid(row[nameidx]))

    date = newmeet.rows[0][newmeet.index('Date')]

    # Try deriving from Birthday first.
    age_from_birthday(newentries, date, birthdays)

    # Otherwise, try deriving from BirthYear.
    age_from_birthyear(newentries, date)
    newentries.remove_column_by_name("BirthYear")

    entriescsv.cat(newentries)
    meetscsv.cat(newmeet)


# Generates the lifters.csv from global state.
def build_lifterscsv(lifterdir, builddir):
    # The map of Name => LifterID has already been populated.
    global LIFTERIDMAP
    assert len(LIFTERIDMAP)

    # Order by LifterID.
    ordered = sorted(LIFTERIDMAP.items(), key=lambda x: x[1])

    # Make a map of (Name => Instagram).
    instagramcsv = Csv(lifterdir + os.sep + 'social-instagram.csv')
    nameidx = instagramcsv.index('Name')
    igidx = instagramcsv.index('Instagram')
    instagram_map = dict()
    for row in instagramcsv.rows:
        instagram_map[row[nameidx]] = row[igidx]
    instagramcsv = None

    # Make a map of (Name => VKontakte).
    vkcsv = Csv(lifterdir + os.sep + 'social-vkontakte.csv')
    nameidx = vkcsv.index('Name')
    vkidx = vkcsv.index('Userpage')
    vk_map = dict()
    for row in vkcsv.rows:
        vk_map[row[nameidx]] = row[vkidx]
    vkcsv = None

    # Make a map of (Name => Color).
    colorcsv = Csv(lifterdir + os.sep + 'supporter-colors.csv')
    nameidx = colorcsv.index('Name')
    coloridx = colorcsv.index('Color')
    colormap = dict()
    for row in colorcsv.rows:
        colormap[row[nameidx]] = row[coloridx]
    colorcsv = None

    lifterscsv = Csv()
    lifterscsv.append_column('LifterID')
    lifterscsv.append_column('Name')
    lifterscsv.append_column('Username')
    lifterscsv.append_column('Instagram')
    lifterscsv.append_column('VKontakte')
    lifterscsv.append_column('Color')

    for (name, lifterid) in ordered:
        instagram = ''
        if name in instagram_map:
            instagram = instagram_map[name]

        vk = ''
        if name in vk_map:
            vk = vk_map[name]

        color = ''
        if name in colormap:
            color = colormap[name]

        username = get_username(name)

        row = [str(lifterid), name, username, instagram, vk, color]
        lifterscsv.rows.append(row)

    lifterscsvpath = builddir + os.sep + 'lifters.csv'
    with open(lifterscsvpath, 'w') as fd:
        lifterscsv.write(fd)


def main(builddir, meetdir, lifterdir):
    entriescsv = Csv()
    meetscsv = Csv()

    # Standardize the column order by hardcoding it here.
    # This is necessary for SQL import statements to work.
    # If this list is modified, also modify scripts/compile-sqlite.
    entriescsv.append_column('MeetID')
    entriescsv.append_column('LifterID')
    entriescsv.append_column('Name')
    entriescsv.append_column('Sex')
    entriescsv.append_column('Event')
    entriescsv.append_column('Equipment')
    entriescsv.append_column('Age')
    entriescsv.append_column('Division')
    entriescsv.append_column('BodyweightKg')
    entriescsv.append_column('WeightClassKg')
    entriescsv.append_column('Squat1Kg')
    entriescsv.append_column('Squat2Kg')
    entriescsv.append_column('Squat3Kg')
    entriescsv.append_column('Squat4Kg')
    entriescsv.append_column('BestSquatKg')
    entriescsv.append_column('Bench1Kg')
    entriescsv.append_column('Bench2Kg')
    entriescsv.append_column('Bench3Kg')
    entriescsv.append_column('Bench4Kg')
    entriescsv.append_column('BestBenchKg')
    entriescsv.append_column('Deadlift1Kg')
    entriescsv.append_column('Deadlift2Kg')
    entriescsv.append_column('Deadlift3Kg')
    entriescsv.append_column('Deadlift4Kg')
    entriescsv.append_column('BestDeadliftKg')
    entriescsv.append_column('TotalKg')
    entriescsv.append_column('Place')
    entriescsv.append_column('Wilks')
    entriescsv.append_column('McCulloch')
    initial_entriescsv_num_columns = len(entriescsv.fieldnames)

    meetscsv.append_column('MeetID')
    meetscsv.append_column('MeetPath')
    meetscsv.append_column('Federation')
    meetscsv.append_column('Date')
    meetscsv.append_column('MeetCountry')
    meetscsv.append_column('MeetState')
    meetscsv.append_column('MeetTown')
    meetscsv.append_column('MeetName')
    initial_meetscsv_num_columns = len(meetscsv.fieldnames)

    birthdays = make_birthdays_map(lifterdir)

    for dirname, subdirs, files in os.walk(meetdir):
        # Modifying `subdirs` in-place will cause the next iteration
        # of the os.walk() generator to operate over the sorted list.
        subdirs.sort()

        if 'entries.csv' in files:
            assert 'meet.csv' in files
            entriespath = dirname + os.sep + 'entries.csv'
            meetpath = dirname + os.sep + 'meet.csv'
            addmeet(entriescsv, meetscsv, entriespath, meetpath, birthdays)

    # Construct the lifters.csv.
    build_lifterscsv(lifterdir, builddir)

    oplcsvpath = builddir + os.sep + 'openpowerlifting.csv'
    meetscsvpath = builddir + os.sep + 'meets.csv'

    with open(oplcsvpath, 'w') as fd:
        entriescsv.write(fd)
    with open(meetscsvpath, 'w') as fd:
        meetscsv.write(fd)

    # If these asserts fail, then new columns have been added.
    # Check the written files: new columns are at the end.
    # Columns need to be explicitly added above to be in a known order,
    # and then scripts/compile-sqlite needs to be notified of the column type.
    assert len(entriescsv.fieldnames) == initial_entriescsv_num_columns
    assert len(meetscsv.fieldnames) == initial_meetscsv_num_columns


if __name__ == '__main__':
    if len(sys.argv) != 4:
        print(' Usage: %s builddir meetdir lifterdir' %
              sys.argv[0], file=sys.stderr)
        sys.exit(1)
    main(sys.argv[1], sys.argv[2], sys.argv[3])
